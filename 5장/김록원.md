# 5장 - 복제(Replication)

# Replication(1) - 복제의 개념과 단일리더 복제, 복제 지연으로 인해 발생 가능한 문제

복제(Replication)란 네트워크로 연결된 여러 장비(노드)에 동일한 데이터의 복사본을 유지하는 것을 의미한다. 복제가 필요하거나 사용하는 이유에는 다음과 같은 것들이 있을 수 있다.
- **지연시간 down** - 지리적으로 사용자와 가깝게 유지
- **가용성 up** - 시스템 일부에 장애가 발생해도 지속적으로 동작
- **읽기 처리량 up** - 읽기 제공 장비 수를 확장해 처리량 늘림

> [!info]- 파티셔닝(샤딩)의 개념을 제외하고 복제에 대한 개념만을 정리한다.
> 즉, 전제 데이터셋을 하나 장비에 모두 저장한다고 가정한다.

복제본을 여러 장비에 유지하는 간단한 목표임에도 복제는 매우 까다롭다. **데이터의 변경과 해당 변경을 다른 복제본에게 전파하는 과정에서 오는 여러가지 어려움** 때문이다. 복제에서 주의 깊게 보아야 하는 상황은 다음과 같다.
- 사용할 수 없는 노드(장애 노드) 발생 및 네트워크 중단의 문제(노드 간 통신 불가 문제)
- 데이터 복제 방식에 따라 발생하는 데이터 일관성, 가용성 문제
- 시스템 내 여러 노드에서 쓰기 작업이 일어날 경우 충돌이 발생하는 문제

복제(Replication)를 사용하는 시스템에서는 위와 같이 모든 사항을 주의 깊게 생각하고 그 결함의 결과를 주의 깊게 다루어야 한다.

하나의 복제 시스템을 구축하는데에 여러가지가 매커니즘이 존재한다. 하나의 노드에만 쓰기를 허용하고 다른 노드는 읽기만 가능한 단일 리더 복제, 여러 노드에서 쓰기가 가능한 다중 리더 복제, 리더의 개념이 존재하지 않는 리더리스 복제 시스템이 존재한다. **네트워크를 통해 각 노드가 분산되어 있어 생기는 복제 지연**과 같은 공통으로 풀어야할 문제도 있으며, 각 시스템 설계가 다름만큼 야기되는 문제가 조금씩 다르기도 하다.


## 단일 리더(리더 - 팔로워)
- 하나의 리더와 여러개의 복제 서버(팔로워)가 존재
- 리더에만 쓰기 작업 가능, 팔로워는 읽기 작업만 수행
- 쓰기 작업은 적지만 읽기 작업이 많은 시스템에 적합
- 리더가 하나만 존재하고 모든 쓰기가 리더를 거쳐야만 하므로, 네트워크 문제와 같은 이유로 리더에 접근하지 못한다면 쓰기 작업이 불가능하다는 단점이 존재
- 다른 두 시스템보다는 상대적으로 구현하기 쉬운 시스템

### 데이터 변경을 팔로워로 복제하는 매커니즘
- 동기식
	- 완전한 동기식은 가용성(Availability)을 떨어트린다.
> [!info] 가용성이란?
> 어떤 문제나 일이 발생하여도 클라이언트에게 멈춤없이 정보를 제공해줄 수 있는지를 의미한다. 가용성이 높다는 것은 시스템 일부에서 문제가 생기더라도 클라이언트가 정보를 받는데 문제가 없다는 의미이다.

- 비동기식
	- 완전한 비동기식은 일관성(Consistency)을 떨어트린다.
> [!info] 일관성이란?
> 어떤 상황에서라도 언제나 같은 데이터를 얻을 수 있음을 의미한다. 리더에 데이터 쓰기 작업이 후 복제 서버로 데이터 변경 전파가 일어난다. 이때 A 복제 서버에 데이터 변경 전파가 완료되기 전에 A 복제 서버로 읽기 요청을 보낸다면, 리더에서 읽은 데이터와 데이터 불일치 문제가 발생한다. 이러한 상황을 '일관성 문제가 발생했다'고 한다.

- 반동기식
	- 하나의 복제 서버에만 동기식으로 동작하고 나머지 복제서버에는 비동기식으로 동작하는 방식이다.
	- 동기식으로 동작하는 복제 서버로 전파가 완료되면 클라이언트에게 응답한다.
	- 강한 일관성을 포기하고 가용성과 함께 최종적 일관성을 얻을 수 있다.
> [!question] 동기식으로 동작하는 복제서버에 문제가 발생한다면?
> 네트워크 이슈나 장애로 인해 해당 복제서버로의 전파가 제대로 이루어지지 않는다면 반동기식도 가용성에 문제가 발생할 것이다. 이런 문제를 사전에 감지하거나 문제가 발생하게 된다면 어떻게 조치할 수 있을까? 타임아웃 방식?

### 팔로워 증설 및 교체 시 데이터 복제
읽기 처리량이 늘거나 기존의 복제 서버에 장애가 발생하여 새로운 팔로워를 만들어야하는 경우가 있다. 여기서 새롭게 만들어지는 팔로워는 대량의 원본 데이터들을 받아야한다. 이와 동시에 **전체 시스템이 중단되지 않는 상태에서 진행**되어야 한다.
1. 리더가 주기적으로 백업한 스냅샷을 일정 시점에서 가져온다.
2. 새로운 팔로워가 이 스냅샷을 복사한다.
3. 새로운 팔로워는 리더와 연결하고 이 스냅샷 이외에 발생한 데이터 변경 건들을 요청한다.
4. 팔로워가 모든 변경건을 처리하게된다면, 이제부턴 다른 팔로워와 마찬가지로 리더에 발생하는 데이터 변화를 전파받아 처리할 수 있다.

### 장애 발생! 장애 복구 처리
어떤 노드에 장애가 발생했느냐에 따라 그 과정이 복잡할 수 있다. 우선 팔로워 노드에 장애가 발생한다면 비교적 장애복구가 쉽다. 팔로워 노드는 동작 시 리더로부터 수시된 데이터 변경 로그를 로컬 디스크에 보관한다. 만약 팔로워 노드에 장애가 발생하여 중단된다면, 재시작 시 데이터 변경 로그에서 마지막 처리한 트랜잭션을 확인한다. 그리고 리더에게 해당 트랜잭션 이후의 데이터 변경을 모두 요청한다. 이 변경이 모두 적용되고나면 이전과 같이 데이터 변경 스트림을 받아 처리한다.

하지만 **리더에 장애가 발생**한다면 그 과정이 까다롭다.(리더의 장애 복구 과정을 Fail over라 부른다) 장애 복구를 위해 신경써야 하는 부분이 많다.
- 팔로워 중 하나를 새로운 리더로 승격
- 클라이언트는 새로운 리더로 쓰기 전송이 일어나도록 재설정
- 팔로워들은 새로운 리더로부터 데이터 변경을 소비하도록 재설정

Fail Over의 단계는 아래와 같이 진행된다.
- 리더의 장애 판단
	- 장애를 판단할 확실한 방법이 없기 때문에 **단순히 타임아웃을 사용**한다.
	- 노드 간 자주 메시지를 주고받으며 일정 시간 동안 응답이 없다면 죽은 것으로 판단한다.
- 리더 선출
	- `합의 알고리즘`을 통해 팔로워 중 하나를 리더로 승격시킨다.
- 클라이언트의 쓰기 전송을 새로운 리더로 재설정 
	- `요청 라우팅`을 통해 기존 리더에서 새로운 리더로 쓰기연산을 전송할 수 있도록 조정한다.
- 팔로워들이 새로운 리더를 바라보도록 설정
	- 기존 장애로 판단된 리더 -> 새로운 리더를 바라보도록 시스템 재설정
	- 기존 장애 중단되었다가 재시작된 이전 리더가 본인이 이젠 리더가 아님을 인식할 수 있도록 해줘야함

> [!warning] 리더 선출을 위한 합의 알고리즘, 요청 라우팅에 대한 공부가 필요

위 단계로 Fail over가 쉽게 해결된다면 좋겠지만 현실은 그렇지 못하다.

> [!warning] 비동기식 데이터 복제를 사용 시 문제점
>  이전 리더가 실패하기 전의 쓰기 작업이 팔로워들에게 전파되지 못한 상황.
>  새로운 리더가 선출되고 이전 리더가 재가동 후 팔로워로 클러스터에 다시 추가되었을때, 해당 데이터가 충돌될 가능성이 있다. 가장 일반적인 해결책은 이전 리더의 복제되지 않은 쓰기를 단순히 폐기하는 방법이다. 하지만 이는 클라이언트의 기대를 저버리게 되는 문제가 있다.

> [!warning] 리더 노드가 2개가 될 가능성
> 이전 리더가 클러스터로 복구 시 본인이 리더가 아님을 인식하지 못한다면 새롭게 선출된 노드와 이전 노드가 스스로 리더라고 믿는 상황이 발생한다. 이러한 상황을 **스플릿 브레인**이라 한다. 이 상황은 두 리더가 쓰기를 받으면서 충돌 해소 과정을 거치지 않는다면 데이터가 유실되거나 오염되는 문제가 발생한다. 이 문제를 해결하기 위해 펜싱 이라고 불리는 메커니즘과 잠금 메커니즘 등이 존재한다.

> [!warning] 리더가 확실하게 죽었다고 판단 가능한 적절한 타임아웃은?
> 일시적인 부하 급중으로 패킷이 지연되는 경우 등을 문제로 설정된 타임아웃보다 응답이 지연되는 경우가 존재한다. 만약 부하로 인한 지연이 문제 였는데 리더가 죽었다 판단하여 장애복구를 진행한다면 오히려 상황이 더 악화될 수 있다.

### 팔로워로 데이터 변경을 전파시키는 방법들
리더에 데이터 변경 작업이 일어나면 복제 서버로 이를 전파해야 한다. 이때 복제 서버로 변경된 데이터를 전파하는 다양한 방식이 존재한다.

- 구문 기반 복제 - 변경 쿼리가 일어났을때 해당 구문(Insert, update delete)을 그대로 복제 서버로 전달한다.
> [!warning] 쿼리 내 비결정적 함수가 있다면 리더와 팔로워의 데이터 불일치 문제가 발생
> 쿼리 실행 시 해당 시간이나 난수를 생성하는 비결정적 함수가 있다면, 리더에서 실행한 것과 팔로워에서 실행한 데이터가 다를 가능성이 높다. 때문에 리더에서 해당 작업들을 미리 계산하여 상수로 바꾼 후 팔로워로 전파한다.

- 쓰기 전 로그 배송 - 모든 쓰기는 db의 로그에 기록된다. 이 로그를 복제서버로 전파한다.
> [!warning] 리더와 읽기DB의 버전이 다른 경우 충돌 문제
> 로그는 저수준의 데이터를 기술한다. 저장소 엔진과 밀접하게 엮이기 때문에 DB의 버전이 다르면 문제가 발생할 수 있다.

- 논리적(로우 기반) 로그 복제 - db의 시스템 로그가 아닌 **다른 로그 형식을 사용**한다.
	- 엔진 내부와 분리함으로써 하위 호환성을 더 쉽게 유지할 수 있다.

- 트리거 기반 복제 - DB가 지원하는 **트리거나 스토어드 프로시저를 이용**해 어플리케이션 코드를 등록하고 해당 코드에서 복제서버로 데이터 변경을 전파한다.
	- 다른 기법들에 비해 오버헤드가 크지만 보다 유연한다.(로그를 직접 커스텀 가능하므로)

---

## 복제 지연으로 인한 문제
보통 데이터 복제하는 과정은 비동기, 반동기로 작업한다. 동기식 작업은 여러 팔로워에게 전파되는 과정 중 네트워크 지연이나 여타의 이유로 지연이 되게 된다면 시스템 전체가 지연되기 때문이다.(가용성 문제) 보통의 어플리케이션에서는 일관성보다는 사용자에게 얼마나 문제없이 빠르게 데이터를 전달할 수 있느냐가 중요하기 때문이기도 하다.

하지만 비동기, 반동기에서는 일관성의 문제가 발생한다. 클라이언트가 변경작업 이후 해당 작업을 읽어올 때, 아직 데이터 변경이 전파되지 않았다면 이전 결과를 얻을 수 있다. 이런 불일치는 일시적인 상태에 불과하고 시간이 흐르면 팔로워가 결국 리더의 변경사항을 따라잡게 된다. 이런 효과를 **최종적 일관성**이라고 한다. 즉, 결국에는 일치가 된다는 의미이다.

대부분의 경우 리더와 팔로워 사이의 지연은 매우 짧은 순간이다. 하지만 부하 증가나 네트워크 문제로 인해 지연이 발생하게 된다면 지연시간은 증가할 수 있다. 이런 상황. 즉, 복제 지연으로 인해 몇가지 문제가 발생할 수 있다.

### 자신이 쓴 내용을 읽기  
데이터변경 이후 곧바로 내 정보를 읽을때 팔로워에 해당 변경 사항이 전파되지 않아 데이터가 없거나 이전 데이터가 불러와지는 문제가 발생
> [!info] 쓰기 후 읽기 일관성이 필요
> 사용자가 쓰기 후 페이지 재로딩 시 항상 자신이 제출한 모든 갱신을 볼 수 있음을 보장하는 것이다. (다른 사용자에 대해서는 보장하지 않는다.)

> [!tip] 사용자가 수정한 내용을 읽을 때는 리더에서 읽기
> 사용자가 수정 가능한 부분에 대해서는 항상 리더에서 읽도록 설정할 수 있다. 예르 들어 본인 프로필 요청과 같은 것들은 유저가 수정 가능한 부분이므로 항상 리더에서 읽도록 설정할 수 있다.

> [!warning] 앱 내의 대부분의 컨텐츠가 사용자가 편집할 가능성이 있다면?
> 이와 같은 경우에는 트래픽이 리더로 몰리므로 팔로워의 효용성이 사라져 비효율적인 상황이다. 이러한 문제로 마지막 갱신 시각을 찾아서 이후 몇 분 동안만 리더에서 읽기를 수행하고 그 이후에는 팔로워로 읽기를 수행시킨다. 이때 클라이언트가 마지막 갱신 시간을 기억한다.

> [!warning] 여러 데이터센터로 운영 중일 때 요청 라우팅 문제
> 리더와 팔로워를 여러 데이터센터에 걸쳐 사용중이라면 리더가 제공해야 하는 모든 요청은 리더가 있는 데이터센터로 라우팅 되어야 한다.

> [!warning] 사용자가 여러 디바이스를 사용하는 문제
> 사용자가 여러 디바이스를 사용하는 경우에는 클라이언트가 마지막 갱신시간을 기억하는 것은 무의미하다. 다른 디바이스로 접속해 자신이 변경한 데이터를 요청할 수 있기 때문이다. 때문에 유저 아이디를 기반한 라우팅을 생각해야할 수도 있다.

### 존재했던 데이터가 사라지는 상황
사용자A가 데이터를 변경하고 해당 변경사항이 팔로워(복제서버)A로 전파 완료하였고 팔로워B로는 아직 전파되지 않은 상황에서 사용자 B가 처음 접속햇을때는 팔로워A에서 정보를 얻었지만 곧바로 새로고침 시에는 팔로워B에서 정보를 얻어 사용자B 입장에서는 있었던 데이터가 사라져 안보이는 상황이 발생할 수 있다. 
> [!tip] 단조 읽기가 필요
> 사용자 ID의 해시를 기반으로 팔로워를 선택한다. 항상 해당 팔로워로 요청을 보낸다.

> [!warning] 사용자B와 매핑된 복제 서버에서 장애가 일어난다면?
> 사용자가 사용중이던 팔로워에 장애가 발생한다면 다른 복제 서버로 재라우팅 시키는 작업이 필요하다.

### 데이터의 순서가 뒤바뀌는 상황(인과성의 문제)
복제보다는 샤딩(데이터를 여러 DB로 분산 저장)된 데이터베이스에서 일어날 수 있는 상황이다. 

A와 B가 주고 받는 대화에서 A의 정보는 파티션A에 저장되고 B의 정보는 파티션B에 저장된다고 할때 각 파티션 내에서 복제 지연이 발생할 수 있다. A의 대화1 이후 B의 대화1이 진행되어도 서로 다른 파티션이기 때문에 전역 순서가 없다. 때문에 제 3자가 해당 대화를 읽을 때 파티션B의 팔로워에 데이터가 먼저 쌓였다면 해당 정보를 먼저 읽고 파티션A에 저장된 정보를 읽는다. 즉, 실제 데이터의 순서를 바꿔 읽게 된다.
> [!warning] 인과성이 있는 데이터의 순서 문제
> 인과성이 있는 데이터의 순서를 보장하기 위해 두 데이터를 동일한 파티션에 기록하게 할 수 있다. 하지만 일부 어플리케이션에서는 효율적이지 않다. 따라서, 인과성을 명시적으로 유지하기 위한 알고리즘을 사용할 수도 있다.(이 부분도 나중에 공부해보자)

> [!question] 인과성이 있는 데이터를 동일한 파티션에 기록하는 것이 부절절한 어플리케이션?
> 인과성이 있는 데이터가 너무 많을 경우, 결국 하나의 파티션으로 몰릴 경우 샤딩의 의미가 없어진다.

# Replication(2) - 다중 리더기반 복제

단일 리더 가반의 시스템에서는 리더가 하나만 존재하고 모든 쓰기가 해당 리더를 거쳐야 한다. 하지만 네트워크 지연 등의 이유로 리더에 접근이 불가능 해지거나 쓰기 트래픽 부하가 증가하게 된다면 쓰기 작업을 하지 못하는 상황이 발생할 수 있다.


### 보통 다중리더의 운영은

![다수의 데이터센터와 각 센터의 리더가 서로 통신하는 이미지 + 리더 위 충돌해소 이미지]()
- 다중 데이터센터를 두고 각 데이터센터마다 하나의 리더를 둔다.
- 각 데이터센터가 독립적으로 운영되고 리더간 통신으로 데이터의 정합성을 맞춘다.
- 이때 데이터 충돌이 일어날 가능성이 있으므로 이를 해결하기도 해야한다.

### 단일리더와 비교한 다중리더의 장점
- 성능 
	- 여러 곳에서 쓰기가 가능하므로 가까운 곳에서 쓰기 작업을 할 수 있음
- 데이터센터 중단 시 내성
	- 각 데이터센터 마다 리더가 존재하므로 쓰기를 하지 못하는 상황은 없음
- 네트워크 문제 내성
	- 일시적이 ㄴ네트워크 중단에도 쓰기 처리를 잘 진행할 수 있다.

### 다중 리더기반 복제와 유사한 사례

![오프라인 작업 후 합쳐지는 이미지]()
- 오프라인 작업을 하는 클라이언트
	- 오프라인 상태에서 작업, 여러 디바이스로 작업, 각 디바이스는 변경사항을 로컬에 저장
	- 온라인에 연결되었을때 각 디바에스에서의 데이터를 동기화
	- 각 디바이스의 로컬 데이터베이스를 하나의 데이터센터로 본다면 다중 리더 기반과 유사함
	- 오프라인 상태 작업 = 데이터센터 간 네트워크 문제 발생 이라고 볼 수 있음
	- 네트워크에 연결 후 각 데이터센터에서의 쓰기 작업을 취합하고 충돌을 해소해야함
- 동시 편집
	- 하나의 페이지에서 여러 유저가 동시에 편집하는 상황
	- 이 상황에서 쓰기 충돌이 일어난다.
	- 한 사람이 쓰기를 할 때 다른 사람의 쓰기를 막으면 단일리더와 같은 상황이 됨
	- 때문에 빠른 협업을 위해 변경 단위를 매우 작게해서 잠금을 피하면 충돌 해소가 필요한 경우를 필요해 다중 리더와 비슷한 문제를 야기한다.

### 쓰기 충돌 다루기

![쓰기 충돌이 일어나는 이미지]()
- 동기, 비동기 충돌 감지
	- 동기식으로 만들면 단일 리더와 다를게 없음.  모든 서버가 쓰기가 복제되기를 기다리는 것이므로
	- 비동기식은 작업 이후 충돌을 감지한다. 다중 쓰기가 가능하지만 이러한 충돌을 해소하는 방법이 필요하다.
- 충돌 회피하기
	- 특정 레코드의 쓰기를 같은 리더(물리적 거리 기반)에서 이뤄지도록 만들기
	- 하지만 유저가 이동하거나 해당 데이터센터에 장애가 발생하면 다른 데이터센터를 이용하게 되고 충돌이 발생한다.
- 일관된 상태로 수렴시키기
	- 고유 ID를 부여하고 이를 이용하거나 타임스탬프를 기반으로 데이터의 순서를 맞춘다. 하지만 네트워크 지연, 신뢰할 수 없는 시계열 등의 문제로 잘못된 순서로 정렬되어 데이터를 유실할 가능성이 있다.
- 사용자 정의 충돌 해소 로직
	- 쓰기 수행 시 해당 이벤트를 받아 바로 빠르게 실행
	- 읽기 수행 시 - 해당 데이터가 호출될때 충돌 해소, 해소된 데이터 저장, 응답 (지연 해소)
- 자동 충돌 해소
	- Operational transformation
	- CRDT

### 리더간 복제 방식 

![복제방식 이미지]()
- 원형 토폴로지
	- 각 리더를 원형으로 연결
	- 무한 복제를 막기 위해 각 노드를 거치면서 복제 로그에 해당 노드의 식별자를 태깅한다.
	- 하나의 리더가 고장나면 전파가 불가능함. 장애 노드를 회피하도록 재설정 할 수 있지만 수동임
- 별 모양 토폴로지
	- 각 리더를 양방향 트리 모델로 연결
	- 무한 복제를 막기 위해 각 노드를 거치면서 복제 로그에 해당 노드의 식별자를 태깅한다.
	- 하나의 리더가 고장나면 전파가 불가능함. 장애 노드를 회피하도록 재설정 할 수 있지만 수동임
- 전체 연결 토폴로지
	- ![3개의 리더와 2명의 유저, A리더에서 insert, C리더가 읽고 수정, 하지만 B리더에 전파될때 C리더의 변경이 선도착]()
	- 모든 리더가 서로 연결되어 있는 형태
	- 내결함성이 가장 우수함
	- 하지만 네트워크 지연시간으로 인해 복제로그가 이전 복제로그를 `추월`할 수 있음. 따라서 복제에서도 일관된 순서로 읽기와 같은 인과성의 문제가 발생할 수 있다.
	- 이런 이벤트를 올바르게 정렬하기 위해 버전 벡터라는 기술을 사용한다.

대부분의 데이터베이스에서 이러한 충돌 해서 기법이 제대로 구현되어 있지 않으므로 다중 리더를 사용하게 된다면 문서를 주의 깊게 읽고 철저하게 테스트 하는 것이 좋다.

# Replication(3) - 리더리스 기반 복제


리더리스 기반 복제는 리더가 존재하지 않는 복제 모델로 AWS의 DynamoDB에서 사용한 후 유행하게 되었다. 리악, 카산드라, 볼드모트가 이 시스템을 사용하며 이런 종류의 데이터베이스들을 **다이나모 스타일**이라고 부르기도 한다.

리더리스 는 모든 노드에 읽기, 쓰기가 가능한 방법이다. 모든 노드에서 쓰기가 일어난다면 데이터의 일관성을 맞추기 어려울텐데 어떻게 이런 모델이 가능한 것일까?

### 리더리스의 동작 방식 - 정족수 일관성
![정족수 읽기 쓰기 이미지]()
리더리스는 클라이언트가 읽기 및 쓰기 작업시 N개의 복제 서버에 모두 요청을 보낸다. 몇 노드에는 성공적으로 쓰기가 이뤄지고 쓰기에 실패하는 노드가 있을 수도 있다. 각 노드들은 데이터에 버전을 가지고 있기 때문에 실패 시 구 버전을 그대로 가지고 있을 것이다. 사용자가 데이터를 읽을 때에도 N개의 노드에 요청을 보내고 요청을 응답을 받았을 때 구버전의 데이터를 가진 노드(쓰기에 실패했던 노드)에 데이터를 새버전으로 업데이트한다.

![정족수가 가지는 의미 - 읽기, 쓰기 그룹이 배타적이지 않게 만들기]()
쓰기를 할때 모든 노드가 성공했을때를 성공으로 보지않고 특정 갯수(W)의 노드에 성공적으로 쓰여진다면 쓰기 성공으로 간주한다. 읽기의 경우에는 특정 갯수(R)의 노드에 질의하고 가장 최신값을 읽는다. 보통 W와 R의 갯수는  `N < W + R` 공식으로 잡는다.(정족수 읽기 쓰기) 이렇게 하면 R개의 노드 중 적어도 하나에서는 가장 최신 값을 읽을 수 있기 때문이다.

### 정족수 일관성에도 한계는 존재한다.
- 느슨한 정족수를 사용한다면 R개의 노드와 W개의 노드가 겹치는 것을 보장하지 않음
- 두 개의 쓰기 발생 시 어떤 쓰기가 먼저 일어났는지 분명하지가 않다. 해당 충돌을 해결해야한다.
- 쓰기, 읽기가 동시에 발생하면 쓰기는 일부 복제 서버에만 발생할 수 있어 읽기에서 최신값을 받았는지 확인이 불분명하다.
- 쓰기가 일부 복제서버에서 디스크 용량 부족과 같은 문제로 실패해도 롤백하지 않는다. 읽기 시 혼란이 올 수도 있다.

### 노드가 고장났을때 복구방법
복제는 최종적으로 모든 데이터가 모든 복제 서버에 복제되어야 한다. 장애로 노드가 중단된 후 온라인 상태가 되었을때 그 사이 누락된 쓰기를 어떻게 따라잡을 수 있을까?
- 읽기 복구
  읽힐 때 클라이언트 측에서 최신값 업데이트
- 안티 엔트로피 처리(잘 안씀)
  백그라운드 프로세스를 두고 복제 서버간 데이터 차이를 지속적으로 찾아 복사(상당한 지연이 발생할 수 있음)

### 정족수가 충족되지 못하는 문제 해결 - 느슨한 정족수, 암시된 핸드오프
N개의 노드 중 쓰기일 땐 최소 W개에서 응답을 받아야하며, 읽기일땐 최소 R에 질의를 보내야 한다. 하지만 N개 중 장애 노드가 여러 발생하거나 네트워크 문제로 W개보다 작아질 때가 있다. 이 상황에서는 정족수를 충족할 수 없다.

이때 클러스터에서 N에 들어가지 않는 일부 데이터베이스에 연결하고 이 노드에 데이터를 저장한다. 이러한 상황을 **느슨한 정족수**라고 부른다. 그리고 장애 상황이 해결되면 이 노드에 저장된 데이터를 장애가 발생했던 노드들에 전송한다. 이 방식을 **암시된 핸드오프**라고 부른다. 하지만 위 상황에서 데이터 읽기 시 N에 포함되지 않고 임시로 차출된 노드에 접근한다는 보장이 없기 때문에 일관성에 문제가 생길 수 있다. 때문에 느슨한 정족수 다이나모 스타일에서도 선택 사항이다.

### 동시 쓰기 감지 & 병합 방법
이전 발생 관계인지 동시성 인지 파악하고 동시성의 경우 클라이언트에게 책임을 미루는 것이 핵심이다.

- 서버측에서 데이터에 버전을 명시함
- 이전 발생 관계인 경우 서버측에서 새로운 버전으로 업데이트함
- 동시 작업인 경우 병합하지 않고 새로운 버전으로 만들고 병합되지 않은 이전 버전도 함께 클라이언트에게 응답함
- 클라이언트는 이후 새로운 요청을 보낼때 새로운 값과 함께 병합할 버전, 현재 자신이 가지고 있는 버전도 함께 요청에 보냄
- 서버에서는 3개를 모두 합쳐 새로운 버전을 만들어냄 - 최종적으로 데이터가 병합됨
- 결과적으로 클라이언트에서 버전을 가지고 병합 처리 요청을 진행해야함

이러한 매커니즘으로 데이터당 버전 번호를 매길 뿐만 아니라 각 데이터베이스 복제본에도 버전을 매겨야 한다. 이렇게 모든 복제본의 버전 번호 모음을 버전 벡터라고 부른다.

> [!question] 단순히 복제본의 버전 번호 모음을 버전 벡터라고 부르는 것인가?
> 

> [!info] 이전 발생 관계와 동시성의 차이
> A라는 작업이 B라는 작업을 알고 진행한다면 이것은 이전 발생 관계가 있는 것이다. 하지만 A 작업이 B 작업의 존재를 모르고 B작어도 A라는 작업을 모르는 채로 작업이 진행되었다면 동시 작업이라고 할 수 있다.


# 스터디

### 기습 퀴즈(2개)
스터디 끝나고 난 후 커밋(답변과 함께)
- Q.
```text
승리: ???
록원: !!!
```  

- Q.
```text
승리: ???
록원: !!!
``` 

### 본인이 이해가 안되었던 부분
- 

### 좀 더 공부한 부분
> [!question] 클라이언트의 역할이 많아 지는 문제
> 리더리스에서는 클라이언트가 모든 노드에 병렬 호출을 할뿐만 아니라 일관성을 확인 후 맞지 않는 노드를 업데이트 해야하는 역할을 맡는다. 클라이언트의 역할이 많아져 이를 대신할 코디네이터 노드를 두기도 한다. 코디네이터 노드가 기존 클라이언트가 맡는 역할을 대신해주며 단일 리더, 다중 리더에서 읽기 시 적절한 팔로워로 요청을 라우팅 하는 역할을 해주기도 한다.

> [!question] 리더가 존재하는 시스템에서의 어떻게 읽기 요청을 적절한 팔로워로 라우팅 시킬 수 있을까?
> 코디네이터 노드가 먼저 요청을 모두 받아 읽기 유저 ID기반, 지리기반으로 적절한 팔로워로 라우팅 시킬 수 있다.

> [!question] 코디네이터가 SPOF가 되는 문제?
> 코디네이터는 요청 라우팅 등의 역할을 맡는 일종의 프록시이다. 하지만 이 코디네이터는 SPOF(단일 장애 지점)이 될 수 있어 노드 중단 시의 대책이 필요하다. 리더 선출과 마찬가지로 시스템 내 다른 노드가 코디데이터로 선출될 수 있도록 설계하는 것이 중요하다.

>[!question] 리더리스의 장점 정리++
>- 일관성 관리
>- 복잡한 분산 트랜잭션 지원

> [!question] 리더리스에서 N개 모두에 읽기, 쓰기를 보낸다면 부하 분산의 효과는 없지 않을까?
> 다수의 노드에게 쓰기와 읽기 요청을 보내므로 부하 분산의 측면에서는 다른 시스템에 비해 제한적이다.

### 논의하고 싶은 부분
- 다중 리더 복제를 사용하게 된다면 어떤 시스템에서 유용할까? 배달의 민족?
